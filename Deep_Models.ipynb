{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoussefDiaa1/Project-ITI/blob/main/Deep_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYf6ZGiKCoWL",
        "outputId": "d4d996c0-e297-4724-8487-f66d1e0b855b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# اختار مسار آمن\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "print(\"Now working inside:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SWJG0iTMhdU",
        "outputId": "86d9c4ac-6d26-4cd8-b422-60060ac4a0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now working inside: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"prepared_data\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Created:\", os.path.abspath(OUTPUT_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4KV2kVlMrR2",
        "outputId": "55397395-a006-445f-86e2-6af6238847d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: /content/prepared_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/prepared_data\n",
        "OUTPUT_DIR = \"/content/prepared_data\"\n"
      ],
      "metadata": {
        "id": "AVuX7efDMY8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "import os\n",
        "import json\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n"
      ],
      "metadata": {
        "id": "AOIGE-PCXzNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- إعدادات ----------\n",
        "AR_FILE = \"/content/drive/MyDrive/ITI_Final_AI_Project/Review_Classification_Data_AR.csv\"\n",
        "EN_FILE = \"/content/drive/MyDrive/ITI_Final_AI_Project/Review_Classification_Data_EN.csv\"\n",
        "OUTPUT_DIR = \"./prepared_data\"\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.1   # نسبة الاختبار النهائية\n",
        "VAL_SIZE = 0.1    # نسبة الفاليدشن من الباقي بعد استقطاع الاختبار\n",
        "OVERSAMPLE = True  # لو True سيقوم بزيادة عينات الفئات الصغيرة\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "ajXRd9_7YY-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_ar(path):\n",
        "    df = pd.read_csv(path)\n",
        "    # نفترض الأعمدة: cleaned_review_description, label\n",
        "    df = df.rename(columns={\"cleaned_review_description\": \"text\", \"label\": \"label\"})\n",
        "    df[\"lang\"] = \"ar\"\n",
        "    # حذف الصفوف الفارغة في النص\n",
        "    df = df[df[\"text\"].notna() & (df[\"text\"].astype(str).str.strip() != \"\")]\n",
        "    return df[[\"text\", \"label\", \"lang\"]]"
      ],
      "metadata": {
        "id": "soOI6bd0YacO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_ar(path):\n",
        "    df = pd.read_csv(path)\n",
        "    # نفترض الأعمدة: cleaned_review_description, label\n",
        "    df = df.rename(columns={\"cleaned_review_description\": \"text\", \"label\": \"label\"})\n",
        "    df[\"lang\"] = \"ar\"\n",
        "    # حذف الصفوف الفارغة في النص\n",
        "    df = df[df[\"text\"].notna() & (df[\"text\"].astype(str).str.strip() != \"\")]\n",
        "    return df[[\"text\", \"label\", \"lang\"]]"
      ],
      "metadata": {
        "id": "vxMHxOLdYblm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_en(path):\n",
        "    df = pd.read_csv(path)\n",
        "    # نفترض الأعمدة: review, sentiment\n",
        "    df = df.rename(columns={\"review\": \"text\", \"sentiment\": \"label\"})\n",
        "    df[\"lang\"] = \"en\"\n",
        "    # لو القيم نصية 'positive'/'negative' نحولهم لأرقام\n",
        "    if df[\"label\"].dtype == object:\n",
        "        df[\"label\"] = df[\"label\"].astype(str).str.strip().str.lower()\n",
        "        df[\"label\"] = df[\"label\"].map({\"negative\": 0, \"positive\": 1}).where(\n",
        "            df[\"label\"].isin([0, 1]), other=df[\"label\"]\n",
        "        )\n",
        "    # حذف الصفوف الفارغة في النص\n",
        "    df = df[df[\"text\"].notna() & (df[\"text\"].astype(str).str.strip() != \"\")]\n",
        "    return df[[\"text\", \"label\", \"lang\"]]"
      ],
      "metadata": {
        "id": "Ss6WxNiXYdFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ar = prepare_ar(AR_FILE)\n",
        "df_en = prepare_en(EN_FILE)\n",
        "\n",
        "df = pd.concat([df_ar, df_en], ignore_index=True)\n",
        "print(\"Merged dataset size:\", len(df))\n",
        "print(\"Languages distribution:\", df[\"lang\"].value_counts().to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK3Asz3hYeT8",
        "outputId": "6ab5d15f-6aca-4ace-af50-54be292d83ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset size: 81079\n",
            "Languages distribution: {'en': 50000, 'ar': 31079}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if df[\"label\"].dtype == object:\n",
        "    df[\"label\"] = df[\"label\"].astype(str).str.strip()\n",
        "    label_values = sorted(df[\"label\"].unique().tolist())\n",
        "    label_map = {lab: i for i, lab in enumerate(label_values)}\n",
        "    df[\"label\"] = df[\"label\"].map(label_map)\n",
        "    # حفظ الـ mapping\n",
        "    with open(os.path.join(OUTPUT_DIR, \"label_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(label_map, f, ensure_ascii=False, indent=2)\n",
        "    print(\"Label mapping (saved):\", label_map)\n",
        "else:\n",
        "    # لو الأرقام 0/1 موجودة، نحفظ خريطة بسيطة\n",
        "    uniques = sorted(df[\"label\"].unique().tolist())\n",
        "    label_map = {str(v): int(v) for v in uniques}\n",
        "    with open(os.path.join(OUTPUT_DIR, \"label_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(label_map, f, ensure_ascii=False, indent=2)\n",
        "    print(\"Numeric labels detected, label_map saved:\", label_map)\n",
        "\n",
        "print(\"Label distribution:\", df[\"label\"].value_counts().to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7CDzNnjYioT",
        "outputId": "8fa78610-581f-4c46-9447-d24f40695eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping (saved): {'0': 0, '1': 1, 'negative': 2, 'positive': 3}\n",
            "Label distribution: {2: 25000, 3: 25000, 1: 18407, 0: 12672}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OVERSAMPLE = True\n",
        "RANDOM_STATE = 42\n",
        "if OVERSAMPLE:\n",
        "    counts = df[\"label\"].value_counts()\n",
        "    max_count = counts.max()\n",
        "    dfs = []\n",
        "    for label_val, group in df.groupby(\"label\"):\n",
        "        if len(group) < max_count:\n",
        "            upsampled = resample(\n",
        "                group,\n",
        "                replace=True,\n",
        "                n_samples=max_count,\n",
        "                random_state=RANDOM_STATE\n",
        "            )\n",
        "            dfs.append(upsampled)\n",
        "        else:\n",
        "            dfs.append(group)\n",
        "    df = pd.concat(dfs).sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
        "    print(\"After oversampling label distribution:\", df[\"label\"].value_counts().to_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR28OKxrYtX6",
        "outputId": "7bb6861a-da74-43a6-a8d1-9a2ee88d6068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After oversampling label distribution: {3: 25000, 0: 25000, 2: 25000, 1: 25000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainval_df, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=df[\"label\"])\n",
        "val_relative_size = VAL_SIZE / (1.0 - TEST_SIZE)\n",
        "train_df, val_df = train_test_split(trainval_df, test_size=val_relative_size, random_state=RANDOM_STATE, stratify=trainval_df[\"label\"])\n",
        "\n",
        "print(\"Final sizes -> train:\", len(train_df), \"val:\", len(val_df), \"test:\", len(test_df))\n",
        "\n",
        "# ---------- حفظ CSVs جاهزة للتدريب (text,label,lang) ----------\n",
        "for name, d in [(\"train.csv\", train_df), (\"validation.csv\", val_df), (\"test.csv\", test_df), (\"merged_all.csv\", df)]:\n",
        "    out_path = os.path.join(OUTPUT_DIR, name)\n",
        "    d[[\"text\", \"label\", \"lang\"]].to_csv(out_path, index=False)\n",
        "    print(\"Saved:\", out_path)\n",
        "\n",
        "print(\"Done. Files in:\", OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PoDBeXyYxw8",
        "outputId": "6d072865-519b-4055-c6e0-0ca34155b684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final sizes -> train: 80000 val: 10000 test: 10000\n",
            "Saved: ./prepared_data/train.csv\n",
            "Saved: ./prepared_data/validation.csv\n",
            "Saved: ./prepared_data/test.csv\n",
            "Saved: ./prepared_data/merged_all.csv\n",
            "Done. Files in: ./prepared_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# إعداد المسارات والمتغيرات\n",
        "# -----------------------------\n",
        "DATA_DIR = \"./prepared_data\"       # المكان اللي فيه CSVs\n",
        "MODEL_NAME = \"xlm-roberta-base\"    # أو \"xlm-roberta-large\" لو GPU كبير\n",
        "OUTPUT_DIR = \"./multilang_model\"\n",
        "NUM_LABELS = 4                     # حسب الـ label mapping اللي عندك\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "s_Bs7R_bWx1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# تحميل البيانات من CSV\n",
        "# -----------------------------\n",
        "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
        "val_df   = pd.read_csv(os.path.join(DATA_DIR, \"validation.csv\"))\n",
        "test_df  = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))"
      ],
      "metadata": {
        "id": "GdBt4yRCWzjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Tokenizer\n",
        "# -----------------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"].tolist(),\n",
        "                     padding=\"max_length\",\n",
        "                     truncation=True,\n",
        "                     max_length=MAX_LEN,\n",
        "                     return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "zmflrYzOW1rs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "4cd7ace11dee490597c46c3edc248c62",
            "736cb325e73a4223b547f4a179eddd9c",
            "e40cefd2c4ea42ffbb29059432435f2f",
            "637221a4087448c983a228b56f605c92",
            "58929daccbe3427f8fa55f7bf93cebb4",
            "09c0ecf95bdb4583b4615732d454772d",
            "700eceb917e74feba6da15c72d87ce05",
            "15489c836cd74a90a6e1f148ac09d465",
            "dac8115633a14d97a164562717728550",
            "4bcdd13adec548b7a6571e0f6256d993",
            "db29d168aa57494da191ef9a9e873062",
            "1951fd231755449fb04dd48181a04659",
            "9a23eedbce26420bba46217e41cab18d",
            "c67a911331544728af5c1f56b1c60e67",
            "02487c6143144e86a15fe8be941bbc13",
            "85ecf03198024687911f5bee682a040c",
            "94c7c39ca709426fa7d8fd5087fe75b9",
            "a300b5fe057e4edbb55a7d43f6d579be",
            "8743674cfb704b08a311cd12b0c1ff49",
            "eb3dc992b8c946f28b55bb3ee8545c19",
            "d6470104461443fe956ca1ed0edfe841",
            "7bdc391bd44044a780a50357edbec55c",
            "16d5fd26f445437284fd5e2ea9bb595d",
            "e71469dc23494b65a7f5ac9c71848407",
            "9ad35f4b5b0244ec98adc10a3be41f51",
            "6bdf6638de184c0d96778f457c35467e",
            "70e9ee4a11374979969d24db17a9a1c9",
            "22872166f0b943af892db2099640b530",
            "a5ed448f43b54bd89004ad257ed7e710",
            "67f503796abf4a6ebab55f4ab586abd7",
            "7a1fcee166474fadad3bf39297ff40d4",
            "1d0e3c03a6d245b580290a2cd4c7b716",
            "40e97b579fe34ab1a93342fe514fb6ce",
            "6ac4fa41db8a45af90619e6154802dd2",
            "a929369a21df41f4b5e6766509c087fe",
            "46eb7adf7f6d4d0a9e7183d8a05e5ad5",
            "15091318b0f84785b569b1dde37b41b8",
            "9f2771b3461d449a86d749d7bc79244d",
            "8f08d7900004432787b10c2a495dccb3",
            "53f869c4030645dfac30f634920e3e0f",
            "322a00f53f9549d78949494e7cc35500",
            "0badfee2c6a04c9f8312817f437566d6",
            "cec9fbd13a7743278dbccbed6f95ff14",
            "3a0a5d8bc71b42b5977ad219c775ad3b"
          ]
        },
        "outputId": "0d9071bb-486f-4413-cab2-dcc6583289d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cd7ace11dee490597c46c3edc248c62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1951fd231755449fb04dd48181a04659"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16d5fd26f445437284fd5e2ea9bb595d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ac4fa41db8a45af90619e6154802dd2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Dataset class لـ Hugging Face\n",
        "# -----------------------------\n",
        "class ReviewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = df[\"text\"].tolist()\n",
        "        self.labels = df[\"label\"].tolist()\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = tokenizer(self.texts[idx],\n",
        "                             padding=\"max_length\",\n",
        "                             truncation=True,\n",
        "                             max_length=MAX_LEN,\n",
        "                             return_tensors=\"pt\")\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "train_dataset = ReviewsDataset(train_df)\n",
        "val_dataset   = ReviewsDataset(val_df)\n",
        "test_dataset  = ReviewsDataset(test_df)"
      ],
      "metadata": {
        "id": "zgIDIbJWW33u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Metrics function\n",
        "# -----------------------------\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
        "        \"precision_macro\": precision_score(labels, preds, average=\"macro\"),\n",
        "        \"recall_macro\": recall_score(labels, preds, average=\"macro\")\n",
        "    }\n"
      ],
      "metadata": {
        "id": "dOhhKUJqW5RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# تحميل موديل للتصنيف\n",
        "# -----------------------------\n",
        "model_T = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9O9XSTPW7xH",
        "outputId": "627dd442-ec37-416f-da3d-b20f68523bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# TrainingArguments\n",
        "# -----------------------------\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    fp16=torch.cuda.is_available()\n",
        ")"
      ],
      "metadata": {
        "id": "104nClodW7p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Trainer\n",
        "# -----------------------------\n",
        "trainer = Trainer(\n",
        "    model=model_T,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "DMxONQ7-W-8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# تدريب الموديل\n",
        "# -----------------------------\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "JFCjnIg3XAD0",
        "outputId": "6b5cabfc-0aa0-4814-b280-fdfd82476f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamrhassanhd\u001b[0m (\u001b[33mamrhassanhd-ieee\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250826_220225-ty5pz2kr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amrhassanhd-ieee/huggingface/runs/ty5pz2kr' target=\"_blank\">curious-disco-2</a></strong> to <a href='https://wandb.ai/amrhassanhd-ieee/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/amrhassanhd-ieee/huggingface' target=\"_blank\">https://wandb.ai/amrhassanhd-ieee/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/amrhassanhd-ieee/huggingface/runs/ty5pz2kr' target=\"_blank\">https://wandb.ai/amrhassanhd-ieee/huggingface/runs/ty5pz2kr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15000/15000 1:10:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.316100</td>\n",
              "      <td>0.303574</td>\n",
              "      <td>0.877000</td>\n",
              "      <td>0.876898</td>\n",
              "      <td>0.878283</td>\n",
              "      <td>0.877000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.266400</td>\n",
              "      <td>0.286916</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>0.895989</td>\n",
              "      <td>0.896185</td>\n",
              "      <td>0.896000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.208200</td>\n",
              "      <td>0.312626</td>\n",
              "      <td>0.901400</td>\n",
              "      <td>0.901383</td>\n",
              "      <td>0.901656</td>\n",
              "      <td>0.901400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=15000, training_loss=0.2893467235565186, metrics={'train_runtime': 4253.1296, 'train_samples_per_second': 56.429, 'train_steps_per_second': 3.527, 'total_flos': 3.157389361152e+16, 'train_loss': 0.2893467235565186, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# تقييم على Test set\n",
        "# -----------------------------\n",
        "results = trainer.evaluate(test_dataset)\n",
        "print(\"Test set results:\", results)"
      ],
      "metadata": {
        "id": "ezlVaKUnXBq9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "0f4b0151-e010-4f9f-a93c-7251d77944ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 54:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set results: {'eval_loss': 0.3137753903865814, 'eval_accuracy': 0.901, 'eval_f1_macro': 0.9009891693486665, 'eval_precision_macro': 0.9011521077161999, 'eval_recall_macro': 0.901, 'eval_runtime': 42.1546, 'eval_samples_per_second': 237.222, 'eval_steps_per_second': 14.826, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# حفظ الموديل النهائي\n",
        "# -----------------------------\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "UrJ2YxBPXC3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ae94fe-8cd4-44f1-fd1a-ba2188a5e391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to ./multilang_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# OUTPUT_DIR = \"./multilang_model\"\n",
        "# ZIP_PATH = OUTPUT_DIR + \".zip\"\n",
        "# shutil.make_archive(OUTPUT_DIR, 'zip', OUTPUT_DIR)\n",
        "\n",
        "# print(\"Created ZIP file:\", ZIP_PATH)\n"
      ],
      "metadata": {
        "id": "CZi1sGXY4o8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import HfApi, upload_folder, create_repo\n",
        "\n",
        "# # تسجيل الدخول\n",
        "# from huggingface_hub import login\n",
        "# login()  # حط الـ token هنا\n",
        "\n",
        "# # اسم الريبو\n",
        "# REPO_ID = \"amrhassank/Review_Classification\"\n",
        "\n",
        "# # إنشاء الريبو لو مش موجود\n",
        "# create_repo(repo_id=REPO_ID, exist_ok=True)  # exist_ok=True مش هيعمل مشكلة لو الريبو موجود بالفعل\n",
        "\n",
        "# # رفع الموديل\n",
        "# OUTPUT_DIR = \"./multilang_model\"\n",
        "# upload_folder(\n",
        "#     repo_id=REPO_ID,\n",
        "#     folder_path=OUTPUT_DIR,\n",
        "#     path_in_repo=\".\"\n",
        "# )\n",
        "\n",
        "# print(\"✅ Model uploaded successfully to:\", f\"https://huggingface.co/{REPO_ID}\")\n"
      ],
      "metadata": {
        "id": "8XZs7GMB6sFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U \"huggingface_hub[cli]\" --quiet\n",
        "# !hf auth login\n",
        "# !hf upload amrhassank/Review_Classification ./multilang_model"
      ],
      "metadata": {
        "id": "Ok-BXxO07ukI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install gradio transformers torch"
      ],
      "metadata": {
        "id": "dldSKL6iq340"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import gradio as gr\n",
        "# import torch\n",
        "# from transformers import pipeline\n",
        "\n",
        "# # -----------------------------\n",
        "# # تحميل الموديل\n",
        "# # -----------------------------\n",
        "# MODEL_PATH = \"./multilang_model\"  # نفس مكان حفظ الموديل\n",
        "# device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# classifier = pipeline(\n",
        "#     \"text-classification\",\n",
        "#     model=MODEL_PATH,\n",
        "#     tokenizer=MODEL_PATH,\n",
        "#     device=device\n",
        "# )\n",
        "# label_map = {\n",
        "#     \"LABEL_0\": \"negative\",\n",
        "#     \"LABEL_1\": \"positive\",\n",
        "#     \"LABEL_2\": \"negative\",\n",
        "#     \"LABEL_3\": \"positive\"\n",
        "# }\n",
        "# # -----------------------------\n",
        "# # دالة التوقع\n",
        "# # -----------------------------\n",
        "# def predict_review(text):\n",
        "#     result = classifier(text)[0]\n",
        "#     label = result[\"label\"]\n",
        "#     score = result[\"score\"]\n",
        "#     mapped_label = label_map.get(label, \"unknown\")\n",
        "#     return f\"Predicted sentiment: {mapped_label}, confidence: {score:.4f}\"\n",
        "\n",
        "# # -----------------------------\n",
        "# # واجهة Gradio\n",
        "# # -----------------------------\n",
        "# interface = gr.Interface(\n",
        "#     fn=predict_review,\n",
        "#     inputs=gr.Textbox(lines=5, placeholder=\"اكتب مراجعة هنا بالعربي أو الإنجليزي...\"),\n",
        "#     outputs=\"text\",\n",
        "#     title=\"Multilingual Review Classifier\",\n",
        "#     description=\"ادخل مراجعة بالإنجليزي أو العربي، واحصل على توقع الإيجابي/السلبي للموديل.\"\n",
        "# )\n",
        "\n",
        "# # تشغيل الواجهة\n",
        "# interface.launch(share=True)  # share=True لو عايز رابط مباشر للويب\n"
      ],
      "metadata": {
        "id": "g8fk1KEhsmI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=\"amrhassank/Review_Classification\")\n",
        "result = classifier(\"This product is amazing!\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "v_Qt5ZzjUaFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=\"amrhassank/Review_Classification\")\n",
        "\n",
        "id2label = {\n",
        "    \"LABEL_0\": \"negative\",\n",
        "    \"LABEL_1\": \"positive\",\n",
        "    \"LABEL_2\": \"negative\",\n",
        "    \"LABEL_3\": \"positive\"\n",
        "}\n",
        "\n",
        "def classify_text(text):\n",
        "    result = classifier(text)[0]\n",
        "    return id2label[result[\"label\"]], float(result[\"score\"])\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify_text,\n",
        "    inputs=gr.Textbox(lines=3, placeholder=\"Enter your review here...\"),\n",
        "    outputs=[\"label\", \"number\"],\n",
        "    title=\"Review Classification\",\n",
        "    description=\"Enter a review and the model will classify it.\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "JsisOoeGUJ4X",
        "outputId": "d2a3da63-3f87-41c9-ebf0-65ff54f5f2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c1318968c457482981.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c1318968c457482981.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "# # اسم النوتبوك المفتوح حاليًا\n",
        "# notebook_path = \"Deep_Models.ipynb\"\n",
        "\n",
        "# # اقرأ النوتبوك\n",
        "# with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
        "#     nb = json.load(f)\n",
        "\n",
        "# # احذف metadata.widgets لو موجود\n",
        "# if \"widgets\" in nb.get(\"metadata\", {}):\n",
        "#     del nb[\"metadata\"][\"widgets\"]\n",
        "#     print(\"Removed metadata.widgets\")\n",
        "\n",
        "# # احفظ النوتبوك مرة أخرى بنفس الاسم\n",
        "# with open(notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(nb, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# print(\"Notebook saved without widgets metadata\")\n"
      ],
      "metadata": {
        "id": "DJSjKOr8bQm4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uH0YsEVRat_h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}